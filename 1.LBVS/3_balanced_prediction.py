# -*- coding: utf-8 -*-
"""3_balanced_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kyJjpYj1GDgbEAgSV1nJNfy54uzw5uJH
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Module Functions"""

'''
    Prediction module
    Use machine learning to predict biding site residues
    Author: Charles Abreu Santana
    Last update: 2020-08-04
'''
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegressionCV
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import preprocessing
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import make_scorer
import pandas as pd
import numpy as np
#import matplotlib.pyplot as plt
from numpy.matlib import repmat
import os
from sklearn.feature_selection import VarianceThreshold
'''
  Class BalancedPrediction
'''
class BalancedPrediction:
    def __init__(self, train_set, drugbank):
        self.train_set = train_set
        self.drugbank = drugbank

    def balanced_prediction(self, clf):
        # split data
        pos_data, neg_data, N_PARTITIONS = self.split_data(self.train_set)
        # shuffle negative index
        permuted_indices = np.random.permutation(len(neg_data))
        # matrix with class values foa all predictions
        # each line is a prediction of one ensenble
        class_matrix = []
        print(N_PARTITIONS, end = ' -> ')
        for i in range(N_PARTITIONS):
            print(i,end=',')
            # Concat positive and a fragment os negative instances
            final_matrix = pd.concat([pos_data, neg_data.iloc[permuted_indices[i::N_PARTITIONS]]])
            # Separa atributos da coluna classe
            class_column = final_matrix.iloc[:,-1]
            final_matrix = final_matrix.iloc[:,:-1]
            new_train_set, new_drugbank_set = self.preprocessing(final_matrix)
            # Training: define model
            class_model = clf.fit(new_train_set, class_column)
            # Prediction: probability_vector 
            probs = class_model.predict_proba(new_drugbank_set)[:,1]
            # voting probabilities
            class_matrix.append(probs)
            # cleaning memory
            del class_model
        return np.array(class_matrix).mean(axis=0)
        # Fzendo predicao final usando a combinacao dos ensembles
        #vector_pred = self.voting(np.array(class_matrix), 0.5)
        #protein.matrix['prediction'] = vector_pred
        #protein.matrix.to_csv(out_dir + os.path.basename(protein.file_name).replace('.pdb', '.csv'), columns=['prediction'])

    def split_data(self, train_data):
        DENOMINATOR = 3
        # rows with positive class
        pos_data = train_data[train_data['class'] == 1]
        # rows with negative class
        neg_data = train_data[train_data['class'] == 0]
        # The number of partitions is set according the positive class length
        proportion = int(len(neg_data)/len(pos_data))
        if proportion < DENOMINATOR:
            n_parts = proportion
        else:
            n_parts = int((len(neg_data)/len(pos_data))/DENOMINATOR)

        return pos_data, neg_data, n_parts


    def preprocessing(self, train_subset):
        # Dado concatenado
        all_data = pd.concat([train_subset, self.drugbank])
        #SVD
        U, s, V = np.linalg.svd(np.transpose(all_data), full_matrices=True)
        # Valores singulares normalizados
        y = s * (1/np.sum(s))
        # Calcula o "joelho" da curva
        rank = get_knee(y)
        # Computa matrix aproximada de posto reduzido
        new_data = low_rank_approximation(s, V , rank)
        # Normalizando os dados
        data_scaled = preprocessing.scale(new_data)
        # Feature Selection
        #data_transformed = VarianceThreshold().fit_transform(data_scaled)
        # separa train_set do drugbank
        new_train_set = data_scaled[:len(train_subset)][:]
        new_drugbank_set = data_scaled[len(train_subset):][:]

        return new_train_set, new_drugbank_set

    # Faz a predição a partir do vetor de probabilidades de um classificador
    def predict_prob(self,prob_vector, threshold):
        pred_vector = []
        for prob in prob_vector:
            if prob < threshold:
                pred_vector.append(0)
            else:
                pred_vector.append(1)
        return pred_vector
        
    # voting using calssification matrix
    def voting(self, binary_matrix, treshold):
        binary_matrix = binary_matrix.T
        confidence = []
        for i in range(binary_matrix.shape[0]):
            # computa a porcentagem de classificadores na votacao
            confidence.append(np.sum(binary_matrix[i])/float(binary_matrix[i].shape[0]))#
        return self.predict_prob(confidence, treshold)

'''
  Funções auxiliares para o SVD
'''
# In: singular values
def get_knee(sgl_values):
    values = list(sgl_values)

    #get coordinates of all the points
    nPoints = len(values)
    allCoord = np.vstack((range(nPoints), values)).T

    # get the first point
    firstPoint = allCoord[0]

    # get vector between first and last point - this is the line
    lineVec = allCoord[-1] - allCoord[0]
    lineVecNorm = lineVec / np.sqrt(np.sum(lineVec**2))
    # find the distance from each point to the line:
    # vector between all points and first point
    vecFromFirst = allCoord - firstPoint
    ''' To calculate the distance to the line, we split vecFromFirst into two
    components, one that is parallel to the line and one that is perpendicular
    Then, we take the norm of the part that is perpendicular to the line and
    get the distance.

    We find the vector parallel to the line by projecting vecFromFirst onto
    the line. The perpendicular vector is vecFromFirst - vecFromFirstParallel
    We project vecFromFirst by taking the scalar product of the vector with
    the unit vector that points in the direction of the line (this gives us
    the length of the projection of vecFromFirst onto the line). If we
    multiply the scalar product by the unit vector, we have vecFromFirstParallel
    '''
    scalarProduct = np.sum(vecFromFirst * repmat(lineVecNorm, nPoints, 1), axis=1)
    vecFromFirstParallel = np.outer(scalarProduct, lineVecNorm)
    vecToLine = vecFromFirst - vecFromFirstParallel

    # distance to line is the norm of vecToLine
    distToLine = np.sqrt(np.sum(vecToLine ** 2, axis=1))

    # knee/elbow is the point with max distance value
    return np.argmax(distToLine) + 1

# In: rank, sigle values and rows
def low_rank_approximation(s, V, rank):
    return np.transpose(np.dot(np.diag(s[:rank]), V[:][:rank]))

"""# Importando dados"""

meu_drive = "/content/drive/My Drive/covid/"
experimento = "LIT/TP53/"

train_set = pd.read_csv(meu_drive + experimento + 'train_set.csv', index_col='name')

test_set = pd.read_csv(meu_drive + experimento +'test_set.csv', index_col='name')

"""# MAIN"""

blc = BalancedPrediction(train_set, test_set.iloc[:,:-1])

#clf = MLPClassifier(alpha=0.0001, learning_rate_init=0.1, max_iter=500, hidden_layer_sizes=(100,75,50,25,)) # COVID
#clf = MLPClassifier(alpha=0.1, learning_rate_init=0.001, max_iter=500) # 5HT, BACE, H1
#clf = KNeighborsClassifier(n_neighbors=3, p=1, weights="distance") # HIV
#clf = MLPClassifier(alpha=0.01, learning_rate_init=0.01, max_iter=500) # H2
clf = ExtraTreesClassifier(bootstrap=True, max_features=0.8, min_samples_leaf=19, min_samples_split=5, n_estimators=200)
  
prob_vector = blc.balanced_prediction(clf)

test_set['prediction'] = prob_vector

print(drugbank.sort_values('prediction', ascending=False).iloc[:10,-1])
#drugbank.sort_values('prediction', ascending=False).to_csv(meu_drive + experimento + experimento[:-1]+'_resultados.csv', columns=['prediction'])

import matplotlib.pyplot as plt
# PLot das probabilidades
fig, ax = plt.subplots()
cutoff = np.zeros(len(prob_vector)) + 0.5
ax.scatter(range(len(prob_vector)), prob_vector, marker='*')
ax.plot(range(len(prob_vector)), cutoff, color='r')
#plt.savefig(meu_drive + experimento + experimento[:-1] + '_probs.jpg')
plt.show()

